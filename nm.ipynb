{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "name": ""
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import openai\nimport sounddevice as sd\nimport numpy as np\nfrom scipy.io import wavfile\nimport tempfile\nimport pyttsx3\nclass VoiceAssistant:\n    \"\"\"\n    This class represents a voice assistant.\n    \n    Attributes:\n        history (list): A list of dictionaries representing the assistant's history.\n        \n    Methods:\n        listen: Records audio from the user and transcribes it.\n        think: Generates a response to the user's input.\n        speak: Converts text to speech and plays it.\n    \"\"\"\n    def __init__(self):\n        # Set your OpenAI API key\n        openai.api_key = \"\"\n        # Initialize the assistant's history\n        self.history = [\n                {\"role\": \"system\", \"content\": \"You are a helpful assistant. The user is english. Only speak english.\"}\n            ]\n        \n    def listen(self):\n        \"\"\"\n        Records audio from the user and transcribes it.\n        \"\"\"\n        print(\"Listening...\")\n        # Record the audio\n        duration = 3  # Record for 3 seconds\n        fs = 44100  # Sample rate\n\n        audio = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype=np.int16)\n        sd.wait()\n\n        # Save the NumPy array to a temporary wav file\n        with tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\") as temp_wav_file:\n            wavfile.write(temp_wav_file.name, fs, audio)\n\n            # Use the temporary wav file in the OpenAI API\n            transcript = openai.Audio.transcribe(\"whisper-1\", temp_wav_file)\n\n        print(f\"User: {transcript['text']}\")\n        return transcript['text']\n\n    def think(self, text):\n        \"\"\"\n        Generates a response to the user's input.\n        \"\"\"\n        # Add the user's input to the assistant's history\n        self.history.append({\"role\": \"user\", \"content\": text})\n        # Send the conversation to the GPT API\n        response = openai.ChatCompletion.create(\n            model=\"gpt-3.5-turbo\",\n            messages=self.history,\n            temperature=0.5\n        )\n        # Extract the assistant's response from the API response\n        message = dict(response.choices[0])['message']['content']\n        self.history.append({\"role\": \"system\", \"content\": message})\n        print('Assistant: ', message)\n        return message\n\n    def speak(self, text):\n        \"\"\"\"\n        Converts text to speech and plays it.\n        \"\"\"\n        # Initialize the speech engine\n        engine = pyttsx3.init()\n\n        # Convert text to speech\n        engine.say(text)\n\n        # Block while processing all currently queued commands\n        engine.runAndWait()\n\n\nif __name__ == \"__main__\":\n    assistant = VoiceAssistant()\n\n    while True:\n        text = assistant.listen()\n\n        if \"goodbye\" in text.strip().lower():\n            print(\"Assistant: Goodbye! Have a great day!\")\n            assistant.speak(\"Goodbye! Have a great day!\")\n            break\n        \n        response = assistant.think(text)\n        assistant.speak(response)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}